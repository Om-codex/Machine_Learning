# ğŸ§  Machine Learning Projects Repository

Welcome to my learning journey in Machine Learning! ğŸš€

This repository documents my progress, from foundational algorithms to end-to-end projects. Here you'll find from-scratch implementations, detailed notebooks, and key insights from various datasets.

---

## ğŸ“Œ Projects & Algorithms Implemented

### ğŸ“Š Regression
* **Advertising Sales Prediction**
    * **Linear Regression** (using Scikit-learn, Normal Equation, and from-scratch Gradient Descent).
    * Optimization with **Batch, Stochastic, and Mini-Batch Gradient Descent**.
    * Regularization with **Ridge, Lasso, and Elastic Net**.
* **Polynomial Regression**
    * Demonstrations of Overfitting and Underfitting.

### ğŸ¯ Classification
* **Fashion-MNIST Image Classification**
    * **Logistic Regression** & **Softmax Regression**.
    * Detailed error analysis using **Confusion Matrices**.
    * Visualization with **Principal Component Analysis (PCA)**.
* **Breast Cancer Diagnosis**
    * **Support Vector Machines (SVM)** with Linear and RBF kernels.
* **Titanic Survival Prediction**
    * **Decision Trees** (including visualization with `dtreeviz`).
* **(In Progress ğŸš§)**
    * Ensemble Methods: **Random Forests, Bagging, Voting**.
    * Boosting Algorithms: **AdaBoost, Gradient Boosting, XGBoost**.

---

## ğŸ’¡ Key Concepts Explored

* **Data Preprocessing:** Feature Scaling, One-Hot Encoding, and Feature Engineering.
* **Model Evaluation:** RÂ² Score (Regression) vs. Accuracy, Precision, Recall, F1-Score, and Classification Reports (Classification).
* **Core Principles:** The Bias-Variance Tradeoff, Overfitting vs. Underfitting, and the importance of Data Quality.
* **Optimization:** Deep dive into Gradient Descent and its variants.

---

## ğŸ› ï¸ Technologies Used

* **Language:** Python
* **Libraries:** Pandas, NumPy, Scikit-learn, TensorFlow (for datasets), Matplotlib, Seaborn, `mlxtend`.
